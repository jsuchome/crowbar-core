#!/bin/bash
#
# After the upgrade of all compute services on all nodes is finished, it's
# necessary to signal all nova services so that they start using latest RPC API version.

LOGFILE=/var/log/crowbar/node-upgrade.log
UPGRADEDIR=/var/lib/crowbar/upgrade
mkdir -p "`dirname "$LOGFILE"`"
exec >>"$LOGFILE" 2>&1

log()
{
    set +x
    echo "[$(date --iso-8601=ns)] [$$] $@"
    set -x
}

log "Executing $BASH_SOURCE"

set -x

mkdir -p $UPGRADEDIR
rm -f $UPGRADEDIR/crowbar-reload-nova-after-upgrade-failed

if [[ -f $UPGRADEDIR/crowbar-reload-nova-after-upgrade-ok ]] ; then
    log "Reload nova script was already successfully executed"
    exit 0
fi

# Check the python-nova package to make sure it is at the latest version with
# no more recent versions in any zypper repositories (this package can be used
# as a proxy for making sure all Nova service packages are up to date since
# they are version locked to python-nova):

if zypper lu -a | grep -w python-nova; then
  echo "There are available update candidates for python-nova. This means that "
  echo "the nova service packages on this node are not at the latest possible "
  echo "version. Please update them and restart the upgrade."

  exit 1
fi

<% if @nova_controller %>
for service in conductor scheduler novncproxy serialproxy api; do
    fullname="openstack-nova-$service"
    systemctl start $fullname
done

# Apache was also stopped by crowbar-stop-nova-services.sh
systemctl start apache2

  <% if @remotes_present and @is_cluster_founder %>
# Start nova-compute on remote nodes:
for remote in $(crm resource list | awk '$1 ~ /^remote-/  {print $1}'); do
  crm resource start $remote
done
  <% end %>

<% else %>
  # Only start on non-remote compute nodes - service on remote nodes will be started by
  # the controller side code above.
  <% unless @is_remote_node %>
systemctl start openstack-nova-compute
  <% end %>
<% end %>

touch $UPGRADEDIR/crowbar-reload-nova-after-upgrade-ok
log "$BASH_SOURCE is finished."
